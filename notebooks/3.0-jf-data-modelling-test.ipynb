{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data Modelling Techniques\n",
    "\n",
    "This notebook is a complete mess. I'll make it clean later on (still testing some stuff).\n",
    "\n",
    "Techniques to be tested:\n",
    "- User2Vec\n",
    "- Network Analysis (Tweets)\n",
    "- Network Analysis (Users)\n",
    "- Popular vs unpopular users identification\n",
    "- Topic Modelling\n",
    "- Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import eland as ed\n",
    "import networkx as nx\n",
    "\n",
    "# uncomment this if database is not already open (and give ES a couple minutes to set up)\n",
    "#!make database\n",
    "\n",
    "es = Elasticsearch(['localhost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty coluns\n",
    "ed_df = ed.read_es('localhost', 'twitter')\n",
    "\n",
    "df = ed_df[\n",
    "    ['tweet_id', 'user_id', 'name', 'full_text_processed',\n",
    "    'original_tweet_id_str', 'quoted_status_id_str', 'in_reply_to_status_id_str',\n",
    "    'is_quote_status', 'is_retweet', 'is_reply', 'is_translator']\n",
    "].to_pandas().fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the annoying scientific notation from id columns\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "def get_source_id(row):\n",
    "    \"\"\"Returns the original Tweet ID from a Quote, Retweet or Reply\"\"\"\n",
    "    if row['is_quote_status']:\n",
    "        return row['quoted_status_id_str']\n",
    "    elif row['is_retweet']:\n",
    "        return row['original_tweet_id_str']\n",
    "    elif row['is_reply']:\n",
    "        return row['in_reply_to_status_id_str']\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['original_tweet_id_str'] = df.apply(get_source_id, axis=1)\n",
    "# I'm counting replies as original posts... Please correct me if you disagree\n",
    "df['is_original'] = ~df[['is_quote_status', 'is_retweet']].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis (Tweets)\n",
    "There is possibly little to no information to be taken from this section, but I kept it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_network = ed_df[\n",
    "#    ['tweet_id', \n",
    "#    'original_tweet_id_str', 'quoted_status_id_str', 'in_reply_to_status_id_str',\n",
    "#    'is_quote_status', 'is_retweet', 'is_reply', 'is_translator', 'is_original']\n",
    "#].to_pandas().fillna(np.nan).rename(columns={'tweet_id': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the annoying scientific notation from id columns\n",
    "# pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "df_network['source'] = df_network.apply(get_source, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263804753286397952</th>\n",
       "      <td>1263801627288521984</td>\n",
       "      <td>1263804753286397952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820895312732160</th>\n",
       "      <td>1263812617430134785</td>\n",
       "      <td>1263820895312732160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820892871618560</th>\n",
       "      <td>1263762563566731264</td>\n",
       "      <td>1263820892871618560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820887897378816</th>\n",
       "      <td>1263788358343499782</td>\n",
       "      <td>1263820887897378816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820880800595968</th>\n",
       "      <td>1263820878783053056</td>\n",
       "      <td>1263820880800595968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850896217092096</th>\n",
       "      <td>1263848854383849477</td>\n",
       "      <td>1263850896217092096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850895160348672</th>\n",
       "      <td>1263848854383849477</td>\n",
       "      <td>1263850895160348672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850832103161856</th>\n",
       "      <td>1263847781094944768</td>\n",
       "      <td>1263850832103161856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850818689740800</th>\n",
       "      <td>1263848064592183298</td>\n",
       "      <td>1263850818689740800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850894912864256</th>\n",
       "      <td>1263493346783309824</td>\n",
       "      <td>1263850894912864256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455471 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source               target  weight\n",
       "1263804753286397952  1263801627288521984  1263804753286397952       1\n",
       "1263820895312732160  1263812617430134785  1263820895312732160       1\n",
       "1263820892871618560  1263762563566731264  1263820892871618560       1\n",
       "1263820887897378816  1263788358343499782  1263820887897378816       1\n",
       "1263820880800595968  1263820878783053056  1263820880800595968       1\n",
       "...                                  ...                  ...     ...\n",
       "1263850896217092096  1263848854383849477  1263850896217092096       1\n",
       "1263850895160348672  1263848854383849477  1263850895160348672       1\n",
       "1263850832103161856  1263847781094944768  1263850832103161856       1\n",
       "1263850818689740800  1263848064592183298  1263850818689740800       1\n",
       "1263850894912864256  1263493346783309824  1263850894912864256       1\n",
       "\n",
       "[455471 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_network['weight'] = 1\n",
    "df_network[['source', 'target', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directed graph\n",
    "G_dir = nx.from_pandas_edgelist(df_network[['source', 'target', 'weight']], create_using=nx.DiGraph())\n",
    "\n",
    "# create an undirected graph\n",
    "G = nx.from_pandas_edgelist(df_network[['source', 'target', 'weight']], create_using=nx.Graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph basic info: 495233 nodes, 455471 edges.\n"
     ]
    }
   ],
   "source": [
    "print(f'Graph basic info: {G_dir.number_of_nodes()} nodes, {G_dir.number_of_edges()} edges.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density measurement: \n",
      "Undirected: 3.71426127592167e-06\n",
      "Directed: 1.857130637960835e-06\n"
     ]
    }
   ],
   "source": [
    "# compare densities of the two graphs\n",
    "print(f'Density measurement: \\nUndirected: {nx.density(G)}\\nDirected: {nx.density(G_dir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out-degree\n",
    "node_attrs=pd.DataFrame.from_dict(dict(G_dir.out_degree()), 'index').rename(columns={0:'out_degree'})\n",
    "\n",
    "#in-degree\n",
    "node_attrs=node_attrs.join(pd.DataFrame.from_dict(dict(G_dir.in_degree()), 'index').rename(columns={0:'in_degree'}))\n",
    "\n",
    "# weighted out-degree\n",
    "#node_attrs=node_attrs.join(pd.DataFrame.from_dict(dict(G_dir.out_degree(weight='weight')), 'index').rename(columns={0:'weighted_out_degree'}))\n",
    "\n",
    "# weighted in-degree\n",
    "#node_attrs=node_attrs.join(pd.DataFrame.from_dict(dict(G_dir.in_degree(weight='weight')), 'index').rename(columns={0:'weighted_in_degree'}))\n",
    "\n",
    "# add tweet ids and original info\n",
    "#node_attrs=node_attrs.join(df.set_index('COMUNE')[[\"COD_REG\",\"COD_CM\", \"COD_PRO\", \"PRO_COM\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out_degree</th>\n",
       "      <th>in_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278816194440605696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401812009810800576</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446602988501491712</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521237811643445184</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495365 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    out_degree  in_degree\n",
       "126                          1          0\n",
       "278816194440605696           1          0\n",
       "401812009810800576           1          0\n",
       "446602988501491712           1          0\n",
       "521237811643445184           1          0\n",
       "...                        ...        ...\n",
       "nan                          1          0\n",
       "nan                          1          0\n",
       "nan                          1          0\n",
       "nan                          1          0\n",
       "nan                          1          0\n",
       "\n",
       "[495365 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_attrs.out_degree.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263804753286397952</th>\n",
       "      <td>1263801627288521984</td>\n",
       "      <td>1263804753286397952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820895312732160</th>\n",
       "      <td>1263812617430134785</td>\n",
       "      <td>1263820895312732160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820892871618560</th>\n",
       "      <td>1263762563566731264</td>\n",
       "      <td>1263820892871618560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820887897378816</th>\n",
       "      <td>1263788358343499782</td>\n",
       "      <td>1263820887897378816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820880800595968</th>\n",
       "      <td>1263820878783053056</td>\n",
       "      <td>1263820880800595968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850896217092096</th>\n",
       "      <td>1263848854383849477</td>\n",
       "      <td>1263850896217092096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850895160348672</th>\n",
       "      <td>1263848854383849477</td>\n",
       "      <td>1263850895160348672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850832103161856</th>\n",
       "      <td>1263847781094944768</td>\n",
       "      <td>1263850832103161856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850818689740800</th>\n",
       "      <td>1263848064592183298</td>\n",
       "      <td>1263850818689740800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263850894912864256</th>\n",
       "      <td>1263493346783309824</td>\n",
       "      <td>1263850894912864256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455471 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source               target  weight\n",
       "1263804753286397952  1263801627288521984  1263804753286397952       1\n",
       "1263820895312732160  1263812617430134785  1263820895312732160       1\n",
       "1263820892871618560  1263762563566731264  1263820892871618560       1\n",
       "1263820887897378816  1263788358343499782  1263820887897378816       1\n",
       "1263820880800595968  1263820878783053056  1263820880800595968       1\n",
       "...                                  ...                  ...     ...\n",
       "1263850896217092096  1263848854383849477  1263850896217092096       1\n",
       "1263850895160348672  1263848854383849477  1263850895160348672       1\n",
       "1263850832103161856  1263847781094944768  1263850832103161856       1\n",
       "1263850818689740800  1263848064592183298  1263850818689740800       1\n",
       "1263850894912864256  1263493346783309824  1263850894912864256       1\n",
       "\n",
       "[455471 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_network[['source', 'target', 'weight']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis (users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network = ed_df[\n",
    "    ['tweet_id', 'name',\n",
    "    'original_tweet_id_str', 'quoted_status_id_str', 'in_reply_to_status_id_str',\n",
    "    'is_quote_status', 'is_retweet', 'is_reply', 'is_translator', 'is_original']\n",
    "].to_pandas().fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['derived.locations.full_name', 'entities.user_mentions.name',\n",
       "       'entities.user_mentions.screen_name', 'name', 'screen_name',\n",
       "       'users_derived_full_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ed_df.columns\n",
    "cols[cols.str.contains('name')]\n",
    "\n",
    "#ed_df[[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User2Vec\n",
    "Based on: https://ieeexplore.ieee.org/document/8875952/\n",
    "\n",
    "How it works:\n",
    "- Run doc2vec\n",
    "- Average vector representations for each user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "# Hyperparameters\n",
    "vector_size = 10\n",
    "min_count = 2\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc2vec = df[[\n",
    "    'tweet_id', 'original_tweet_id_str', \n",
    "    'user_id', 'name', 'full_text_processed', \n",
    "]][df['is_original']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>original_tweet_id_str</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263804753286397952</th>\n",
       "      <td>1263804753286397952</td>\n",
       "      <td>1263801627288521984</td>\n",
       "      <td>2739781807</td>\n",
       "      <td>Debjani Bhattacharyya</td>\n",
       "      <td>66 km embankment breached yes need quickly rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820880800595968</th>\n",
       "      <td>1263820880800595968</td>\n",
       "      <td>1263820878783053056</td>\n",
       "      <td>81572564</td>\n",
       "      <td>Malcolm Sen</td>\n",
       "      <td>crisis singular event yet another chapter unfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820878783053824</th>\n",
       "      <td>1263820878783053824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81572564</td>\n",
       "      <td>Malcolm Sen</td>\n",
       "      <td>utter devastation kolkata wake state fails res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820864967135232</th>\n",
       "      <td>1263820864967135232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1214239561598951428</td>\n",
       "      <td>AfricaZilla</td>\n",
       "      <td>prayer thought love affected cyclone amphan sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263820862827958272</th>\n",
       "      <td>1263820862827958272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2165333665</td>\n",
       "      <td>Savi</td>\n",
       "      <td>image west bengal tragic water monsoon way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                tweet_id original_tweet_id_str  \\\n",
       "1263804753286397952  1263804753286397952   1263801627288521984   \n",
       "1263820880800595968  1263820880800595968   1263820878783053056   \n",
       "1263820878783053824  1263820878783053824                   NaN   \n",
       "1263820864967135232  1263820864967135232                   NaN   \n",
       "1263820862827958272  1263820862827958272                   NaN   \n",
       "\n",
       "                                 user_id                   name  \\\n",
       "1263804753286397952           2739781807  Debjani Bhattacharyya   \n",
       "1263820880800595968             81572564            Malcolm Sen   \n",
       "1263820878783053824             81572564            Malcolm Sen   \n",
       "1263820864967135232  1214239561598951428            AfricaZilla   \n",
       "1263820862827958272           2165333665                   Savi   \n",
       "\n",
       "                                                   full_text_processed  \n",
       "1263804753286397952  66 km embankment breached yes need quickly rep...  \n",
       "1263820880800595968  crisis singular event yet another chapter unfo...  \n",
       "1263820878783053824  utter devastation kolkata wake state fails res...  \n",
       "1263820864967135232  prayer thought love affected cyclone amphan sh...  \n",
       "1263820862827958272         image west bengal tragic water monsoon way  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc, tag=None):\n",
    "    \"\"\"Tokenizes a single tweet.\"\"\"\n",
    "    tokens = simple_preprocess(doc)\n",
    "    if tag is None:\n",
    "        return tokens\n",
    "    else:\n",
    "        return TaggedDocument(tokens, [tag])\n",
    "\n",
    "train_corpus = [tokenize(doc, tag) for doc, tag in zip(df_doc2vec['full_text_processed'], range(df_doc2vec.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:15:30,211 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-08-13 00:15:30,245 : INFO : collecting all words and their counts\n",
      "2020-08-13 00:15:30,266 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-08-13 00:15:30,731 : INFO : PROGRESS: at example #10000, processed 131046 words (296138/s), 12137 word types, 10000 tags\n",
      "2020-08-13 00:15:30,937 : INFO : PROGRESS: at example #20000, processed 260493 words (632493/s), 18266 word types, 20000 tags\n",
      "2020-08-13 00:15:31,048 : INFO : PROGRESS: at example #30000, processed 384004 words (1123313/s), 23084 word types, 30000 tags\n",
      "2020-08-13 00:15:31,182 : INFO : PROGRESS: at example #40000, processed 502154 words (889773/s), 26517 word types, 40000 tags\n",
      "2020-08-13 00:15:31,292 : INFO : PROGRESS: at example #50000, processed 622138 words (1100278/s), 29657 word types, 50000 tags\n",
      "2020-08-13 00:15:31,484 : INFO : PROGRESS: at example #60000, processed 760279 words (722515/s), 35397 word types, 60000 tags\n",
      "2020-08-13 00:15:31,594 : INFO : PROGRESS: at example #70000, processed 886777 words (1162240/s), 39521 word types, 70000 tags\n",
      "2020-08-13 00:15:31,695 : INFO : PROGRESS: at example #80000, processed 1014846 words (1270235/s), 42452 word types, 80000 tags\n",
      "2020-08-13 00:15:31,842 : INFO : PROGRESS: at example #90000, processed 1146246 words (914659/s), 45214 word types, 90000 tags\n",
      "2020-08-13 00:15:31,938 : INFO : PROGRESS: at example #100000, processed 1278853 words (1403958/s), 47990 word types, 100000 tags\n",
      "2020-08-13 00:15:31,999 : INFO : collected 49778 word types and 104775 unique tags from a corpus of 104775 examples and 1349510 words\n",
      "2020-08-13 00:15:32,000 : INFO : Loading a fresh vocabulary\n",
      "2020-08-13 00:15:32,148 : INFO : effective_min_count=2 retains 22162 unique words (44% of original 49778, drops 27616)\n",
      "2020-08-13 00:15:32,149 : INFO : effective_min_count=2 leaves 1321894 word corpus (97% of original 1349510, drops 27616)\n",
      "2020-08-13 00:15:32,265 : INFO : deleting the raw counts dictionary of 49778 items\n",
      "2020-08-13 00:15:32,272 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2020-08-13 00:15:32,274 : INFO : downsampling leaves estimated 1120526 word corpus (84.8% of prior 1321894)\n",
      "2020-08-13 00:15:32,395 : INFO : estimated required memory for 22162 words and 10 dimensions: 17044960 bytes\n",
      "2020-08-13 00:15:32,396 : INFO : resetting layer weights\n",
      "2020-08-13 00:16:05,968 : INFO : training model with 3 workers on 22162 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-08-13 00:16:07,068 : INFO : EPOCH 1 - PROGRESS: at 11.66% examples, 135173 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:08,130 : INFO : EPOCH 1 - PROGRESS: at 24.89% examples, 139941 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:09,134 : INFO : EPOCH 1 - PROGRESS: at 37.14% examples, 141079 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:10,179 : INFO : EPOCH 1 - PROGRESS: at 50.81% examples, 144520 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:11,186 : INFO : EPOCH 1 - PROGRESS: at 62.42% examples, 145103 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:12,211 : INFO : EPOCH 1 - PROGRESS: at 75.91% examples, 147336 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:13,296 : INFO : EPOCH 1 - PROGRESS: at 89.61% examples, 149015 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:13,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:14,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:14,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:14,080 : INFO : EPOCH - 1 : training on 1349510 raw words (1225231 effective words) took 8.1s, 151500 effective words/s\n",
      "2020-08-13 00:16:15,130 : INFO : EPOCH 2 - PROGRESS: at 12.43% examples, 149063 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:16,156 : INFO : EPOCH 2 - PROGRESS: at 27.71% examples, 162756 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:16:17,190 : INFO : EPOCH 2 - PROGRESS: at 41.23% examples, 157736 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:18,191 : INFO : EPOCH 2 - PROGRESS: at 54.90% examples, 161460 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:19,205 : INFO : EPOCH 2 - PROGRESS: at 67.80% examples, 159865 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:20,223 : INFO : EPOCH 2 - PROGRESS: at 81.96% examples, 161262 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:21,226 : INFO : EPOCH 2 - PROGRESS: at 96.78% examples, 165310 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:21,393 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:21,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:21,501 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:21,502 : INFO : EPOCH - 2 : training on 1349510 raw words (1225287 effective words) took 7.4s, 165455 effective words/s\n",
      "2020-08-13 00:16:22,549 : INFO : EPOCH 3 - PROGRESS: at 12.43% examples, 148874 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:23,551 : INFO : EPOCH 3 - PROGRESS: at 27.04% examples, 160213 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:24,639 : INFO : EPOCH 3 - PROGRESS: at 41.91% examples, 158976 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:25,669 : INFO : EPOCH 3 - PROGRESS: at 56.34% examples, 163460 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:26,680 : INFO : EPOCH 3 - PROGRESS: at 71.25% examples, 166911 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:16:27,725 : INFO : EPOCH 3 - PROGRESS: at 85.26% examples, 166393 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:28,671 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:28,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:28,696 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:28,699 : INFO : EPOCH - 3 : training on 1349510 raw words (1224929 effective words) took 7.2s, 170489 effective words/s\n",
      "2020-08-13 00:16:29,764 : INFO : EPOCH 4 - PROGRESS: at 13.89% examples, 168236 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:30,792 : INFO : EPOCH 4 - PROGRESS: at 28.95% examples, 172281 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:31,811 : INFO : EPOCH 4 - PROGRESS: at 44.18% examples, 170554 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:32,885 : INFO : EPOCH 4 - PROGRESS: at 57.93% examples, 168301 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:33,898 : INFO : EPOCH 4 - PROGRESS: at 72.63% examples, 170705 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:34,909 : INFO : EPOCH 4 - PROGRESS: at 86.79% examples, 170515 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:35,771 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:35,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:35,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:35,849 : INFO : EPOCH - 4 : training on 1349510 raw words (1225002 effective words) took 7.1s, 172344 effective words/s\n",
      "2020-08-13 00:16:36,885 : INFO : EPOCH 5 - PROGRESS: at 12.43% examples, 150089 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:37,903 : INFO : EPOCH 5 - PROGRESS: at 27.04% examples, 159676 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:38,981 : INFO : EPOCH 5 - PROGRESS: at 39.59% examples, 150526 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:40,042 : INFO : EPOCH 5 - PROGRESS: at 50.24% examples, 142477 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:41,054 : INFO : EPOCH 5 - PROGRESS: at 60.47% examples, 139725 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:42,087 : INFO : EPOCH 5 - PROGRESS: at 71.92% examples, 139935 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:43,098 : INFO : EPOCH 5 - PROGRESS: at 86.18% examples, 144030 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:16:44,048 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:44,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:44,114 : INFO : EPOCH 5 - PROGRESS: at 100.00% examples, 148400 words/s, in_qsize 0, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:16:44,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:44,115 : INFO : EPOCH - 5 : training on 1349510 raw words (1225136 effective words) took 8.3s, 148376 effective words/s\n",
      "2020-08-13 00:16:45,136 : INFO : EPOCH 6 - PROGRESS: at 12.43% examples, 152831 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:16:46,175 : INFO : EPOCH 6 - PROGRESS: at 27.08% examples, 159303 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:47,228 : INFO : EPOCH 6 - PROGRESS: at 42.61% examples, 163226 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:48,260 : INFO : EPOCH 6 - PROGRESS: at 56.34% examples, 164365 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:16:49,270 : INFO : EPOCH 6 - PROGRESS: at 71.92% examples, 169461 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:50,348 : INFO : EPOCH 6 - PROGRESS: at 87.47% examples, 170552 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:51,137 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:51,213 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:51,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:51,220 : INFO : EPOCH - 6 : training on 1349510 raw words (1225155 effective words) took 7.1s, 172730 effective words/s\n",
      "2020-08-13 00:16:52,340 : INFO : EPOCH 7 - PROGRESS: at 13.89% examples, 155593 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:53,428 : INFO : EPOCH 7 - PROGRESS: at 29.70% examples, 165358 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:16:54,431 : INFO : EPOCH 7 - PROGRESS: at 45.93% examples, 169522 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:55,465 : INFO : EPOCH 7 - PROGRESS: at 61.12% examples, 173791 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:56,535 : INFO : EPOCH 7 - PROGRESS: at 75.12% examples, 171107 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:57,619 : INFO : EPOCH 7 - PROGRESS: at 88.92% examples, 169040 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:16:58,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:16:58,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:16:58,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:16:58,397 : INFO : EPOCH - 7 : training on 1349510 raw words (1225225 effective words) took 7.2s, 171032 effective words/s\n",
      "2020-08-13 00:16:59,466 : INFO : EPOCH 8 - PROGRESS: at 9.44% examples, 112710 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:00,502 : INFO : EPOCH 8 - PROGRESS: at 21.34% examples, 126130 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:01,505 : INFO : EPOCH 8 - PROGRESS: at 30.58% examples, 120332 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:02,520 : INFO : EPOCH 8 - PROGRESS: at 45.08% examples, 129791 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:03,539 : INFO : EPOCH 8 - PROGRESS: at 59.46% examples, 139744 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:04,558 : INFO : EPOCH 8 - PROGRESS: at 73.48% examples, 144810 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:05,564 : INFO : EPOCH 8 - PROGRESS: at 83.94% examples, 142054 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:06,595 : INFO : EPOCH 8 - PROGRESS: at 98.61% examples, 147515 words/s, in_qsize 3, out_qsize 0\n",
      "2020-08-13 00:17:06,604 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:06,629 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:06,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:06,645 : INFO : EPOCH - 8 : training on 1349510 raw words (1224886 effective words) took 8.2s, 148877 effective words/s\n",
      "2020-08-13 00:17:07,699 : INFO : EPOCH 9 - PROGRESS: at 14.65% examples, 175348 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:08,702 : INFO : EPOCH 9 - PROGRESS: at 30.58% examples, 182562 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:09,712 : INFO : EPOCH 9 - PROGRESS: at 45.93% examples, 177926 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:10,754 : INFO : EPOCH 9 - PROGRESS: at 58.77% examples, 172839 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:11,795 : INFO : EPOCH 9 - PROGRESS: at 75.12% examples, 176816 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:12,831 : INFO : EPOCH 9 - PROGRESS: at 88.92% examples, 175028 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:13,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:13,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:13,522 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:13,532 : INFO : EPOCH - 9 : training on 1349510 raw words (1225315 effective words) took 6.9s, 178429 effective words/s\n",
      "2020-08-13 00:17:14,722 : INFO : EPOCH 10 - PROGRESS: at 13.89% examples, 146793 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:15,744 : INFO : EPOCH 10 - PROGRESS: at 28.27% examples, 156907 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:16,788 : INFO : EPOCH 10 - PROGRESS: at 44.27% examples, 161848 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:17,874 : INFO : EPOCH 10 - PROGRESS: at 60.47% examples, 167933 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:18,899 : INFO : EPOCH 10 - PROGRESS: at 74.31% examples, 168000 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:19,907 : INFO : EPOCH 10 - PROGRESS: at 88.92% examples, 169806 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:20,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:20,615 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:20,664 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:20,665 : INFO : EPOCH - 10 : training on 1349510 raw words (1225478 effective words) took 7.1s, 172210 effective words/s\n",
      "2020-08-13 00:17:21,708 : INFO : EPOCH 11 - PROGRESS: at 15.49% examples, 184119 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:22,709 : INFO : EPOCH 11 - PROGRESS: at 30.58% examples, 182801 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:23,755 : INFO : EPOCH 11 - PROGRESS: at 46.74% examples, 178809 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:24,783 : INFO : EPOCH 11 - PROGRESS: at 63.04% examples, 185709 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:25,859 : INFO : EPOCH 11 - PROGRESS: at 78.96% examples, 183669 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:26,878 : INFO : EPOCH 11 - PROGRESS: at 95.45% examples, 187123 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:27,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:27,171 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:27,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:27,187 : INFO : EPOCH - 11 : training on 1349510 raw words (1225548 effective words) took 6.5s, 188207 effective words/s\n",
      "2020-08-13 00:17:28,258 : INFO : EPOCH 12 - PROGRESS: at 13.89% examples, 162658 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:29,323 : INFO : EPOCH 12 - PROGRESS: at 30.58% examples, 175038 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:30,364 : INFO : EPOCH 12 - PROGRESS: at 47.54% examples, 176803 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:31,380 : INFO : EPOCH 12 - PROGRESS: at 62.42% examples, 180151 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:32,423 : INFO : EPOCH 12 - PROGRESS: at 78.08% examples, 180448 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:33,444 : INFO : EPOCH 12 - PROGRESS: at 93.90% examples, 182880 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:33,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:33,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:33,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:33,820 : INFO : EPOCH - 12 : training on 1349510 raw words (1224962 effective words) took 6.6s, 184999 effective words/s\n",
      "2020-08-13 00:17:34,841 : INFO : EPOCH 13 - PROGRESS: at 14.65% examples, 180429 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:17:35,897 : INFO : EPOCH 13 - PROGRESS: at 30.58% examples, 180287 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:36,985 : INFO : EPOCH 13 - PROGRESS: at 48.22% examples, 180527 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:38,008 : INFO : EPOCH 13 - PROGRESS: at 63.74% examples, 184926 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:39,018 : INFO : EPOCH 13 - PROGRESS: at 78.96% examples, 183581 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:40,048 : INFO : EPOCH 13 - PROGRESS: at 95.45% examples, 186739 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:40,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:40,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:40,334 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:40,335 : INFO : EPOCH - 13 : training on 1349510 raw words (1224627 effective words) took 6.5s, 188474 effective words/s\n",
      "2020-08-13 00:17:41,408 : INFO : EPOCH 14 - PROGRESS: at 15.49% examples, 178289 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:42,451 : INFO : EPOCH 14 - PROGRESS: at 31.46% examples, 180640 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:43,507 : INFO : EPOCH 14 - PROGRESS: at 48.25% examples, 179793 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:44,523 : INFO : EPOCH 14 - PROGRESS: at 63.74% examples, 184666 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:45,534 : INFO : EPOCH 14 - PROGRESS: at 76.64% examples, 178200 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:46,543 : INFO : EPOCH 14 - PROGRESS: at 90.33% examples, 176975 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:47,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:47,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:47,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:47,328 : INFO : EPOCH - 14 : training on 1349510 raw words (1225173 effective words) took 7.0s, 175416 effective words/s\n",
      "2020-08-13 00:17:48,429 : INFO : EPOCH 15 - PROGRESS: at 15.49% examples, 175219 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:49,491 : INFO : EPOCH 15 - PROGRESS: at 29.70% examples, 168904 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:17:50,513 : INFO : EPOCH 15 - PROGRESS: at 45.08% examples, 168176 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:51,519 : INFO : EPOCH 15 - PROGRESS: at 59.77% examples, 171656 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:52,524 : INFO : EPOCH 15 - PROGRESS: at 73.48% examples, 171740 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:53,548 : INFO : EPOCH 15 - PROGRESS: at 88.92% examples, 173958 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:54,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:17:54,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:17:54,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:17:54,279 : INFO : EPOCH - 15 : training on 1349510 raw words (1225152 effective words) took 6.9s, 176674 effective words/s\n",
      "2020-08-13 00:17:55,324 : INFO : EPOCH 16 - PROGRESS: at 13.89% examples, 166568 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:56,327 : INFO : EPOCH 16 - PROGRESS: at 28.39% examples, 169077 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:57,373 : INFO : EPOCH 16 - PROGRESS: at 44.18% examples, 169880 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:58,389 : INFO : EPOCH 16 - PROGRESS: at 58.77% examples, 172355 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:17:59,403 : INFO : EPOCH 16 - PROGRESS: at 74.31% examples, 175693 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:00,403 : INFO : EPOCH 16 - PROGRESS: at 88.16% examples, 175083 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:01,104 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:01,130 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:01,137 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:01,138 : INFO : EPOCH - 16 : training on 1349510 raw words (1225157 effective words) took 6.8s, 178904 effective words/s\n",
      "2020-08-13 00:18:02,152 : INFO : EPOCH 17 - PROGRESS: at 14.65% examples, 180399 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:03,203 : INFO : EPOCH 17 - PROGRESS: at 30.58% examples, 180845 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:04,211 : INFO : EPOCH 17 - PROGRESS: at 46.74% examples, 179732 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:05,222 : INFO : EPOCH 17 - PROGRESS: at 62.42% examples, 184921 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:06,265 : INFO : EPOCH 17 - PROGRESS: at 78.08% examples, 184228 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:07,281 : INFO : EPOCH 17 - PROGRESS: at 93.90% examples, 186228 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:07,571 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:07,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:07,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:07,637 : INFO : EPOCH - 17 : training on 1349510 raw words (1224901 effective words) took 6.5s, 188725 effective words/s\n",
      "2020-08-13 00:18:08,692 : INFO : EPOCH 18 - PROGRESS: at 15.49% examples, 182933 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:09,696 : INFO : EPOCH 18 - PROGRESS: at 30.58% examples, 181953 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:10,702 : INFO : EPOCH 18 - PROGRESS: at 45.93% examples, 177699 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:11,739 : INFO : EPOCH 18 - PROGRESS: at 62.42% examples, 184354 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:12,837 : INFO : EPOCH 18 - PROGRESS: at 78.96% examples, 183533 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:13,862 : INFO : EPOCH 18 - PROGRESS: at 95.45% examples, 186812 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:14,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:14,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:14,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:14,149 : INFO : EPOCH - 18 : training on 1349510 raw words (1224967 effective words) took 6.5s, 188546 effective words/s\n",
      "2020-08-13 00:18:15,164 : INFO : EPOCH 19 - PROGRESS: at 15.49% examples, 189130 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:16,213 : INFO : EPOCH 19 - PROGRESS: at 31.46% examples, 185382 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:17,260 : INFO : EPOCH 19 - PROGRESS: at 47.54% examples, 180351 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:18,281 : INFO : EPOCH 19 - PROGRESS: at 63.04% examples, 185006 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:19,362 : INFO : EPOCH 19 - PROGRESS: at 78.96% examples, 182886 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:20,371 : INFO : EPOCH 19 - PROGRESS: at 94.70% examples, 185332 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:20,672 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:20,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:20,706 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:20,707 : INFO : EPOCH - 19 : training on 1349510 raw words (1224926 effective words) took 6.5s, 187087 effective words/s\n",
      "2020-08-13 00:18:21,747 : INFO : EPOCH 20 - PROGRESS: at 12.43% examples, 149394 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:22,813 : INFO : EPOCH 20 - PROGRESS: at 16.29% examples, 94897 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:23,925 : INFO : EPOCH 20 - PROGRESS: at 29.83% examples, 113078 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:25,026 : INFO : EPOCH 20 - PROGRESS: at 46.74% examples, 127820 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:26,051 : INFO : EPOCH 20 - PROGRESS: at 63.04% examples, 142993 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:27,063 : INFO : EPOCH 20 - PROGRESS: at 78.96% examples, 149966 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:18:28,097 : INFO : EPOCH 20 - PROGRESS: at 94.70% examples, 155998 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:28,363 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:28,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:28,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:28,387 : INFO : EPOCH - 20 : training on 1349510 raw words (1225302 effective words) took 7.7s, 159721 effective words/s\n",
      "2020-08-13 00:18:29,423 : INFO : EPOCH 21 - PROGRESS: at 14.74% examples, 176963 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:30,495 : INFO : EPOCH 21 - PROGRESS: at 30.58% examples, 177494 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:31,553 : INFO : EPOCH 21 - PROGRESS: at 47.44% examples, 177634 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:32,567 : INFO : EPOCH 21 - PROGRESS: at 63.04% examples, 183084 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:33,625 : INFO : EPOCH 21 - PROGRESS: at 78.96% examples, 182199 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:34,659 : INFO : EPOCH 21 - PROGRESS: at 94.70% examples, 183988 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:34,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:34,919 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:34,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:34,934 : INFO : EPOCH - 21 : training on 1349510 raw words (1225681 effective words) took 6.5s, 187536 effective words/s\n",
      "2020-08-13 00:18:35,964 : INFO : EPOCH 22 - PROGRESS: at 15.49% examples, 186554 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:36,998 : INFO : EPOCH 22 - PROGRESS: at 30.58% examples, 181104 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:38,042 : INFO : EPOCH 22 - PROGRESS: at 47.54% examples, 180838 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:39,051 : INFO : EPOCH 22 - PROGRESS: at 63.04% examples, 185909 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:40,114 : INFO : EPOCH 22 - PROGRESS: at 75.91% examples, 177320 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:41,136 : INFO : EPOCH 22 - PROGRESS: at 91.69% examples, 180218 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:41,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:41,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:41,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:41,623 : INFO : EPOCH - 22 : training on 1349510 raw words (1225679 effective words) took 6.7s, 183523 effective words/s\n",
      "2020-08-13 00:18:42,670 : INFO : EPOCH 23 - PROGRESS: at 15.49% examples, 183092 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:43,815 : INFO : EPOCH 23 - PROGRESS: at 30.58% examples, 170295 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:44,816 : INFO : EPOCH 23 - PROGRESS: at 43.37% examples, 161706 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:45,824 : INFO : EPOCH 23 - PROGRESS: at 54.78% examples, 157726 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:46,896 : INFO : EPOCH 23 - PROGRESS: at 68.49% examples, 156888 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:47,900 : INFO : EPOCH 23 - PROGRESS: at 81.30% examples, 156166 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:48,948 : INFO : EPOCH 23 - PROGRESS: at 96.12% examples, 159829 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:49,120 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:49,127 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:49,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:49,149 : INFO : EPOCH - 23 : training on 1349510 raw words (1225106 effective words) took 7.5s, 162961 effective words/s\n",
      "2020-08-13 00:18:50,168 : INFO : EPOCH 24 - PROGRESS: at 15.49% examples, 188792 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:51,205 : INFO : EPOCH 24 - PROGRESS: at 30.58% examples, 181847 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:52,211 : INFO : EPOCH 24 - PROGRESS: at 46.74% examples, 180573 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:53,222 : INFO : EPOCH 24 - PROGRESS: at 56.34% examples, 167277 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:54,318 : INFO : EPOCH 24 - PROGRESS: at 69.93% examples, 163669 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:55,385 : INFO : EPOCH 24 - PROGRESS: at 85.26% examples, 166067 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:56,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:18:56,434 : INFO : EPOCH 24 - PROGRESS: at 99.31% examples, 167199 words/s, in_qsize 1, out_qsize 1\n",
      "2020-08-13 00:18:56,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:18:56,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:18:56,443 : INFO : EPOCH - 24 : training on 1349510 raw words (1225165 effective words) took 7.3s, 168232 effective words/s\n",
      "2020-08-13 00:18:57,516 : INFO : EPOCH 25 - PROGRESS: at 11.66% examples, 136497 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:18:58,553 : INFO : EPOCH 25 - PROGRESS: at 22.24% examples, 129431 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:18:59,617 : INFO : EPOCH 25 - PROGRESS: at 33.10% examples, 125886 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:00,789 : INFO : EPOCH 25 - PROGRESS: at 42.61% examples, 116717 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:01,797 : INFO : EPOCH 25 - PROGRESS: at 51.33% examples, 114961 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:02,825 : INFO : EPOCH 25 - PROGRESS: at 64.61% examples, 122533 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:03,868 : INFO : EPOCH 25 - PROGRESS: at 78.96% examples, 128386 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:04,894 : INFO : EPOCH 25 - PROGRESS: at 90.33% examples, 129996 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:05,939 : INFO : EPOCH 25 - PROGRESS: at 98.61% examples, 127199 words/s, in_qsize 3, out_qsize 0\n",
      "2020-08-13 00:19:05,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:06,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:06,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:06,082 : INFO : EPOCH - 25 : training on 1349510 raw words (1225434 effective words) took 9.6s, 127256 effective words/s\n",
      "2020-08-13 00:19:07,129 : INFO : EPOCH 26 - PROGRESS: at 13.89% examples, 168093 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:08,168 : INFO : EPOCH 26 - PROGRESS: at 26.36% examples, 153722 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:09,211 : INFO : EPOCH 26 - PROGRESS: at 41.23% examples, 157138 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:10,236 : INFO : EPOCH 26 - PROGRESS: at 52.49% examples, 153206 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:11,300 : INFO : EPOCH 26 - PROGRESS: at 65.50% examples, 152067 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:12,322 : INFO : EPOCH 26 - PROGRESS: at 78.96% examples, 153110 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:13,331 : INFO : EPOCH 26 - PROGRESS: at 92.25% examples, 155671 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:13,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:13,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:13,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:13,866 : INFO : EPOCH - 26 : training on 1349510 raw words (1225621 effective words) took 7.8s, 157919 effective words/s\n",
      "2020-08-13 00:19:14,902 : INFO : EPOCH 27 - PROGRESS: at 13.89% examples, 167803 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:15,981 : INFO : EPOCH 27 - PROGRESS: at 29.70% examples, 172293 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:17,002 : INFO : EPOCH 27 - PROGRESS: at 45.08% examples, 170418 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:18,025 : INFO : EPOCH 27 - PROGRESS: at 59.77% examples, 172728 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:19:19,099 : INFO : EPOCH 27 - PROGRESS: at 71.92% examples, 166895 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:20,114 : INFO : EPOCH 27 - PROGRESS: at 86.79% examples, 168663 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:21,115 : INFO : EPOCH 27 - PROGRESS: at 98.65% examples, 166749 words/s, in_qsize 2, out_qsize 1\n",
      "2020-08-13 00:19:21,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:21,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:21,165 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:21,165 : INFO : EPOCH - 27 : training on 1349510 raw words (1225328 effective words) took 7.3s, 168082 effective words/s\n",
      "2020-08-13 00:19:22,215 : INFO : EPOCH 28 - PROGRESS: at 13.89% examples, 165700 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:23,281 : INFO : EPOCH 28 - PROGRESS: at 29.70% examples, 172279 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:24,315 : INFO : EPOCH 28 - PROGRESS: at 46.74% examples, 175456 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:25,332 : INFO : EPOCH 28 - PROGRESS: at 61.75% examples, 179103 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:26,339 : INFO : EPOCH 28 - PROGRESS: at 77.33% examples, 180883 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:27,441 : INFO : EPOCH 28 - PROGRESS: at 90.28% examples, 175074 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:28,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:28,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:28,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:28,090 : INFO : EPOCH - 28 : training on 1349510 raw words (1225324 effective words) took 6.9s, 177185 effective words/s\n",
      "2020-08-13 00:19:29,113 : INFO : EPOCH 29 - PROGRESS: at 13.89% examples, 170156 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:30,155 : INFO : EPOCH 29 - PROGRESS: at 29.70% examples, 176655 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:31,207 : INFO : EPOCH 29 - PROGRESS: at 45.93% examples, 174477 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:32,223 : INFO : EPOCH 29 - PROGRESS: at 58.77% examples, 171483 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:33,300 : INFO : EPOCH 29 - PROGRESS: at 71.92% examples, 167679 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:34,302 : INFO : EPOCH 29 - PROGRESS: at 85.26% examples, 166720 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:35,302 : INFO : EPOCH 29 - PROGRESS: at 98.61% examples, 167594 words/s, in_qsize 3, out_qsize 0\n",
      "2020-08-13 00:19:35,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:35,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:35,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:35,389 : INFO : EPOCH - 29 : training on 1349510 raw words (1225537 effective words) took 7.3s, 168151 effective words/s\n",
      "2020-08-13 00:19:36,453 : INFO : EPOCH 30 - PROGRESS: at 13.89% examples, 164843 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:37,518 : INFO : EPOCH 30 - PROGRESS: at 28.39% examples, 163360 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:38,551 : INFO : EPOCH 30 - PROGRESS: at 43.37% examples, 163908 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:39,655 : INFO : EPOCH 30 - PROGRESS: at 58.03% examples, 164243 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:40,658 : INFO : EPOCH 30 - PROGRESS: at 72.63% examples, 167814 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:41,735 : INFO : EPOCH 30 - PROGRESS: at 87.47% examples, 167785 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:42,489 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:42,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:42,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:42,540 : INFO : EPOCH - 30 : training on 1349510 raw words (1225393 effective words) took 7.1s, 171801 effective words/s\n",
      "2020-08-13 00:19:43,567 : INFO : EPOCH 31 - PROGRESS: at 14.65% examples, 178610 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:44,577 : INFO : EPOCH 31 - PROGRESS: at 30.58% examples, 183753 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:45,585 : INFO : EPOCH 31 - PROGRESS: at 46.74% examples, 181728 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:46,589 : INFO : EPOCH 31 - PROGRESS: at 61.75% examples, 184487 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:47,635 : INFO : EPOCH 31 - PROGRESS: at 77.33% examples, 183788 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:48,669 : INFO : EPOCH 31 - PROGRESS: at 92.98% examples, 185326 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:19:49,011 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:49,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:49,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:49,082 : INFO : EPOCH - 31 : training on 1349510 raw words (1225217 effective words) took 6.5s, 187648 effective words/s\n",
      "2020-08-13 00:19:50,097 : INFO : EPOCH 32 - PROGRESS: at 15.49% examples, 189555 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:51,114 : INFO : EPOCH 32 - PROGRESS: at 30.58% examples, 184130 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:52,124 : INFO : EPOCH 32 - PROGRESS: at 45.89% examples, 178774 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:53,152 : INFO : EPOCH 32 - PROGRESS: at 61.78% examples, 183420 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:54,187 : INFO : EPOCH 32 - PROGRESS: at 76.64% examples, 181629 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:55,229 : INFO : EPOCH 32 - PROGRESS: at 92.25% examples, 183327 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:55,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:19:55,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:19:55,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:19:55,693 : INFO : EPOCH - 32 : training on 1349510 raw words (1225412 effective words) took 6.6s, 185690 effective words/s\n",
      "2020-08-13 00:19:56,724 : INFO : EPOCH 33 - PROGRESS: at 14.65% examples, 177803 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:57,753 : INFO : EPOCH 33 - PROGRESS: at 30.58% examples, 181592 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:58,800 : INFO : EPOCH 33 - PROGRESS: at 47.54% examples, 180914 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:19:59,823 : INFO : EPOCH 33 - PROGRESS: at 63.04% examples, 185286 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:00,892 : INFO : EPOCH 33 - PROGRESS: at 78.08% examples, 181794 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:01,968 : INFO : EPOCH 33 - PROGRESS: at 94.70% examples, 183878 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:02,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:02,296 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:02,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:02,302 : INFO : EPOCH - 33 : training on 1349510 raw words (1225254 effective words) took 6.6s, 185749 effective words/s\n",
      "2020-08-13 00:20:03,313 : INFO : EPOCH 34 - PROGRESS: at 13.89% examples, 171990 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:04,385 : INFO : EPOCH 34 - PROGRESS: at 30.58% examples, 179350 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:05,418 : INFO : EPOCH 34 - PROGRESS: at 47.54% examples, 180145 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:06,470 : INFO : EPOCH 34 - PROGRESS: at 63.04% examples, 183432 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:07,500 : INFO : EPOCH 34 - PROGRESS: at 78.96% examples, 183408 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:08,517 : INFO : EPOCH 34 - PROGRESS: at 94.70% examples, 185479 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:08,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:20:08,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:08,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:08,825 : INFO : EPOCH - 34 : training on 1349510 raw words (1224891 effective words) took 6.5s, 188034 effective words/s\n",
      "2020-08-13 00:20:09,839 : INFO : EPOCH 35 - PROGRESS: at 14.65% examples, 181243 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:10,865 : INFO : EPOCH 35 - PROGRESS: at 30.58% examples, 183487 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:11,901 : INFO : EPOCH 35 - PROGRESS: at 47.54% examples, 182826 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:12,921 : INFO : EPOCH 35 - PROGRESS: at 62.42% examples, 184618 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:13,932 : INFO : EPOCH 35 - PROGRESS: at 78.08% examples, 185124 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:14,946 : INFO : EPOCH 35 - PROGRESS: at 92.98% examples, 185595 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:15,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:15,341 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:15,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:15,357 : INFO : EPOCH - 35 : training on 1349510 raw words (1225258 effective words) took 6.5s, 187957 effective words/s\n",
      "2020-08-13 00:20:16,439 : INFO : EPOCH 36 - PROGRESS: at 15.49% examples, 177252 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:17,443 : INFO : EPOCH 36 - PROGRESS: at 31.46% examples, 183454 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:18,499 : INFO : EPOCH 36 - PROGRESS: at 47.44% examples, 178761 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:19,510 : INFO : EPOCH 36 - PROGRESS: at 62.42% examples, 181958 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:20,578 : INFO : EPOCH 36 - PROGRESS: at 78.08% examples, 180935 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:21,623 : INFO : EPOCH 36 - PROGRESS: at 93.90% examples, 182642 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:21,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:21,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:21,954 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:21,955 : INFO : EPOCH - 36 : training on 1349510 raw words (1225297 effective words) took 6.6s, 185982 effective words/s\n",
      "2020-08-13 00:20:23,078 : INFO : EPOCH 37 - PROGRESS: at 16.20% examples, 179814 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:24,103 : INFO : EPOCH 37 - PROGRESS: at 32.37% examples, 182697 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:25,151 : INFO : EPOCH 37 - PROGRESS: at 48.92% examples, 181770 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:26,167 : INFO : EPOCH 37 - PROGRESS: at 64.61% examples, 186077 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:27,188 : INFO : EPOCH 37 - PROGRESS: at 79.70% examples, 184124 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:28,204 : INFO : EPOCH 37 - PROGRESS: at 95.45% examples, 186172 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:28,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:28,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:28,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:28,476 : INFO : EPOCH - 37 : training on 1349510 raw words (1225628 effective words) took 6.5s, 188366 effective words/s\n",
      "2020-08-13 00:20:29,520 : INFO : EPOCH 38 - PROGRESS: at 13.89% examples, 166885 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:30,649 : INFO : EPOCH 38 - PROGRESS: at 29.70% examples, 167855 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:31,658 : INFO : EPOCH 38 - PROGRESS: at 45.03% examples, 168118 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:32,666 : INFO : EPOCH 38 - PROGRESS: at 59.77% examples, 171565 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:33,690 : INFO : EPOCH 38 - PROGRESS: at 75.12% examples, 174431 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:34,693 : INFO : EPOCH 38 - PROGRESS: at 90.33% examples, 176874 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:35,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:35,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:35,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:35,368 : INFO : EPOCH - 38 : training on 1349510 raw words (1225220 effective words) took 6.9s, 178092 effective words/s\n",
      "2020-08-13 00:20:36,385 : INFO : EPOCH 39 - PROGRESS: at 15.49% examples, 190135 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:37,396 : INFO : EPOCH 39 - PROGRESS: at 30.58% examples, 184854 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:38,398 : INFO : EPOCH 39 - PROGRESS: at 46.74% examples, 182838 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:39,468 : INFO : EPOCH 39 - PROGRESS: at 63.04% examples, 186848 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:40,512 : INFO : EPOCH 39 - PROGRESS: at 78.96% examples, 185644 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:41,513 : INFO : EPOCH 39 - PROGRESS: at 93.78% examples, 186467 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:41,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:41,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:41,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:41,839 : INFO : EPOCH - 39 : training on 1349510 raw words (1225567 effective words) took 6.5s, 189878 effective words/s\n",
      "2020-08-13 00:20:42,916 : INFO : EPOCH 40 - PROGRESS: at 13.89% examples, 162187 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:43,942 : INFO : EPOCH 40 - PROGRESS: at 30.58% examples, 178154 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:45,024 : INFO : EPOCH 40 - PROGRESS: at 47.54% examples, 176601 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:46,031 : INFO : EPOCH 40 - PROGRESS: at 63.04% examples, 182637 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:47,051 : INFO : EPOCH 40 - PROGRESS: at 78.96% examples, 183181 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-13 00:20:48,059 : INFO : EPOCH 40 - PROGRESS: at 94.70% examples, 185622 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-13 00:20:48,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-13 00:20:48,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-13 00:20:48,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-13 00:20:48,419 : INFO : EPOCH - 40 : training on 1349510 raw words (1225311 effective words) took 6.6s, 186680 effective words/s\n",
      "2020-08-13 00:20:48,424 : INFO : training on a 53980400 raw words (49009682 effective words) took 282.4s, 173525 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "model = Doc2Vec(vector_size=vector_size, min_count=min_count, epochs=epochs)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_cols = [f'doc2vec_{i}' for i in range(vector_size)]\n",
    "\n",
    "doc_vectors = df_doc2vec['full_text_processed'].apply(\n",
    "    lambda doc: np.expand_dims(\n",
    "        model.infer_vector(tokenize(doc)), axis=0\n",
    "    )\n",
    ")\n",
    "df_vectors = pd.DataFrame(\n",
    "    np.concatenate(doc_vectors, 0), columns=doc2vec_cols\n",
    ").set_index(df_doc2vec.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user2vec = df[[\n",
    "    'tweet_id', 'original_tweet_id_str',\n",
    "    'user_id', 'name', 'full_text_processed', \n",
    "]][~df['is_original']].copy()\n",
    "\n",
    "def get_vectors(tweet_id):\n",
    "    try:\n",
    "        return df_doc2vec.loc[\n",
    "            tweet_id, \n",
    "            doc2vec_cols\n",
    "        ]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "_vectors = df_user2vec['original_tweet_id_str'].apply(get_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: original_tweet_id_str, dtype: object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_vectors[~_vectors.isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109417, 12), (82378,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['is_retweet']].shape, df[~df['is_retweet']]['full_text_processed'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83811,), (104775, 5), (78658,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text_processed'].unique().shape, df_doc2vec.shape, df_doc2vec['full_text_processed'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.263801627288522e+18'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_tweet_id_str'].astype(str).loc['1263804753286397952']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1263788358343499782'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1263788358343499782'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-23b4bb1030dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.float_format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'%.0f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_tweet_id_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3480\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1263788358343499782'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "df.loc[str(int(df['original_tweet_id_str'].iloc[200]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'user_id', 'original_tweet_id_str', 'quoted_status_id_str',\n",
       "       'in_reply_to_status_id_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.columns.str.contains('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
