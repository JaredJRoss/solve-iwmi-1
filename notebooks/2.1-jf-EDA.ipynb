{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This notebook performs an initial EDA based on the sample data extracted during the data pull and etl steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import eland as ed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_dir = join(os.getcwd(), os.pardir)\n",
    "raw_dir = join(project_dir, 'data', 'raw')\n",
    "interim_dir = join(project_dir, 'data', 'interim')\n",
    "db_name = 'data_pull_sample.db'\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ed_df = ed.read_es('localhost', 'twitter')\n",
    "df_twt = ed_df.to_pandas()\n",
    "df_users = df_twt.loc[\n",
    "    :,\n",
    "    list(df_twt.columns[df_twt.columns.str.startswith('user')]) + ['verified', 'protected']\n",
    "].copy().drop_duplicates('user_id')\n",
    "\n",
    "df_twt['is_original'] = ~df_twt[['is_retweet', 'is_quote_status', 'is_reply']].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Questions:\n",
    "- How many tweets are in the dataset?\n",
    "- How many unique tweets are in the dataset?\n",
    "- How many unique users?\n",
    "- Number of retweets\n",
    "- Locate the top N retweeted and liked tweets and the users that posted them\n",
    "- What are the locations? (Number of tweets by location)\n",
    "- What are the main languages? What are the counts and proportions of tweets by languages?\n",
    "- Location over time\n",
    "- Source analysis\n",
    "- Protected\n",
    "- Verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Tweet Analysis\n",
    "### How many tweets are in the dataset? How many unique tweets are in the dataset? Number of retweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of Tweets:\t\t474419\n",
      "Number of original Tweets:\t94018\n",
      "Number of retweets:\t\t361077\n",
      "Number of replies:\t\t14478\n",
      "Number of quotes:\t\t14190\n",
      "\n",
      "Note: Many of the quote statuses/tweets are both marked as quotes and retweets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Total number of Tweets:\\t\\t{df_twt.shape[0]}\n",
    "Number of original Tweets:\\t{df_twt.is_original.sum()}\n",
    "Number of retweets:\\t\\t{df_twt.is_retweet.sum()}\n",
    "Number of replies:\\t\\t{df_twt.is_reply.sum()}\n",
    "Number of quotes:\\t\\t{df_twt.is_quote_status.sum()}\n",
    "\n",
    "Note: Many of the quote statuses/tweets are both marked as quotes and retweets.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the top N retweeted and liked tweets and the users that posted them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1268202497216319488</td>\n",
       "      <td>https://t.co/sFwcDyxcgA</td>\n",
       "      <td>59487</td>\n",
       "      <td>Ratan N. Tata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262797667677212672</td>\n",
       "      <td>We need a president who believes in science.</td>\n",
       "      <td>42995</td>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1263213348000325632</td>\n",
       "      <td>u up? @NASA</td>\n",
       "      <td>27047</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1263091517767536640</td>\n",
       "      <td>Well done @RubikaLiyaquat for standing up for ...</td>\n",
       "      <td>26243</td>\n",
       "      <td>Sudhir Chaudhary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1263828899575758848</td>\n",
       "      <td>15 yr old Jyoti Kumari, carried her wounded fa...</td>\n",
       "      <td>24152</td>\n",
       "      <td>Ivanka Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1263815469145788416</td>\n",
       "      <td>Deeply saddened by the loss of life due to a p...</td>\n",
       "      <td>21544</td>\n",
       "      <td>Narendra Modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1263516296093863936</td>\n",
       "      <td>If you reply to this tweet I’ll give you $10,000!</td>\n",
       "      <td>18841</td>\n",
       "      <td>MrBeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1266152680428236800</td>\n",
       "      <td>I have lost control of the situation.</td>\n",
       "      <td>18489</td>\n",
       "      <td>God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1264121291365216256</td>\n",
       "      <td>घटना : मध्यप्रदेश के छिंदवाड़ा जिले के पिपला थ...</td>\n",
       "      <td>16721</td>\n",
       "      <td>Devvesh Pandey | देवेश पांडेय | دیویش پانڈے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1263320513276817408</td>\n",
       "      <td>एक सच्चे देशभक्त,उदार और परोपकारी पिता के पुत्...</td>\n",
       "      <td>16609</td>\n",
       "      <td>Rahul Gandhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1263108871314235392</td>\n",
       "      <td>I would rather hear Trump's brutal truths than...</td>\n",
       "      <td>15719</td>\n",
       "      <td>Charlie Kirk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1263828248250576896</td>\n",
       "      <td>I’m sorry to hear about the air crash in Pakis...</td>\n",
       "      <td>15457</td>\n",
       "      <td>Rahul Gandhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1268206270168723456</td>\n",
       "      <td>Humanity has failed again...........\\nOne of m...</td>\n",
       "      <td>13763</td>\n",
       "      <td>Sudarsan Pattnaik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1262772783467188224</td>\n",
       "      <td>Daily carbon emissions declined 17% between Ja...</td>\n",
       "      <td>13557</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1263176697190526976</td>\n",
       "      <td>15 homes torched by Indian Occupation forces i...</td>\n",
       "      <td>13285</td>\n",
       "      <td>Imran Khan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1262792224284332032</td>\n",
       "      <td>इधर से बस भेजो ,\\nउधर से टेम्पो निकलेगा ,\\nवैज...</td>\n",
       "      <td>12761</td>\n",
       "      <td>Babita Phogat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1262969124227035136</td>\n",
       "      <td>Nazma Aapi on Corona at Zee News. https://t.co...</td>\n",
       "      <td>12698</td>\n",
       "      <td>Saloni Gaur (Nazma Aapi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1262940130576302080</td>\n",
       "      <td>It would make every Indian proud that the numb...</td>\n",
       "      <td>12262</td>\n",
       "      <td>Narendra Modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1263309240875102208</td>\n",
       "      <td>On his death anniversary, tributes to former P...</td>\n",
       "      <td>11084</td>\n",
       "      <td>Narendra Modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1267150918165749760</td>\n",
       "      <td>Creepy noises heard in Bryan Texas with lightn...</td>\n",
       "      <td>11043</td>\n",
       "      <td>LU$T//OWAI$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                          full_text  \\\n",
       "0   1268202497216319488                            https://t.co/sFwcDyxcgA   \n",
       "1   1262797667677212672       We need a president who believes in science.   \n",
       "2   1263213348000325632                                        u up? @NASA   \n",
       "3   1263091517767536640  Well done @RubikaLiyaquat for standing up for ...   \n",
       "4   1263828899575758848  15 yr old Jyoti Kumari, carried her wounded fa...   \n",
       "5   1263815469145788416  Deeply saddened by the loss of life due to a p...   \n",
       "6   1263516296093863936  If you reply to this tweet I’ll give you $10,000!   \n",
       "7   1266152680428236800              I have lost control of the situation.   \n",
       "8   1264121291365216256  घटना : मध्यप्रदेश के छिंदवाड़ा जिले के पिपला थ...   \n",
       "9   1263320513276817408  एक सच्चे देशभक्त,उदार और परोपकारी पिता के पुत्...   \n",
       "10  1263108871314235392  I would rather hear Trump's brutal truths than...   \n",
       "11  1263828248250576896  I’m sorry to hear about the air crash in Pakis...   \n",
       "12  1268206270168723456  Humanity has failed again...........\\nOne of m...   \n",
       "13  1262772783467188224  Daily carbon emissions declined 17% between Ja...   \n",
       "14  1263176697190526976  15 homes torched by Indian Occupation forces i...   \n",
       "15  1262792224284332032  इधर से बस भेजो ,\\nउधर से टेम्पो निकलेगा ,\\nवैज...   \n",
       "16  1262969124227035136  Nazma Aapi on Corona at Zee News. https://t.co...   \n",
       "17  1262940130576302080  It would make every Indian proud that the numb...   \n",
       "18  1263309240875102208  On his death anniversary, tributes to former P...   \n",
       "19  1267150918165749760  Creepy noises heard in Bryan Texas with lightn...   \n",
       "\n",
       "    retweet_count                                          name  \n",
       "0           59487                                 Ratan N. Tata  \n",
       "1           42995                                     Joe Biden  \n",
       "2           27047                                       Twitter  \n",
       "3           26243                              Sudhir Chaudhary  \n",
       "4           24152                                  Ivanka Trump  \n",
       "5           21544                                 Narendra Modi  \n",
       "6           18841                                       MrBeast  \n",
       "7           18489                                           God  \n",
       "8           16721  Devvesh Pandey | देवेश पांडेय | دیویش پانڈے۔  \n",
       "9           16609                                  Rahul Gandhi  \n",
       "10          15719                                  Charlie Kirk  \n",
       "11          15457                                  Rahul Gandhi  \n",
       "12          13763                             Sudarsan Pattnaik  \n",
       "13          13557                                           CNN  \n",
       "14          13285                                    Imran Khan  \n",
       "15          12761                                 Babita Phogat  \n",
       "16          12698                      Saloni Gaur (Nazma Aapi)  \n",
       "17          12262                                 Narendra Modi  \n",
       "18          11084                                 Narendra Modi  \n",
       "19          11043                                   LU$T//OWAI$  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 20\n",
    "df_twt[df_twt.is_original==True]\\\n",
    "    .nlargest(N, 'retweet_count')\\\n",
    "    [['tweet_id', 'full_text', 'retweet_count', 'name']]\\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the locations? (Number of tweets by location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location', 'users_derived_locality'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twt.columns[df_twt.columns.str.contains('loca')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please note that 140614 tweets (~29% of the dataset) do not contain location info.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>31746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kolkata, India</th>\n",
       "      <td>14966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Delhi, India</th>\n",
       "      <td>12825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mumbai, India</th>\n",
       "      <td>6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bengal, India</th>\n",
       "      <td>4748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kolkata</th>\n",
       "      <td>4061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Delhi</th>\n",
       "      <td>3223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bengaluru, India</th>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>भारत</th>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mumbai</th>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Khajuraho</th>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyderabad, India</th>\n",
       "      <td>2285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bhubaneshwar, India</th>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dhaka, Bangladesh</th>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pune, India</th>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lucknow, India</th>\n",
       "      <td>1873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patna, India</th>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uttar Pradesh, India</th>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDIA</th>\n",
       "      <td>1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delhi</th>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count\n",
       "Location                   \n",
       "India                 31746\n",
       "Kolkata, India        14966\n",
       "New Delhi, India      12825\n",
       "Mumbai, India          6983\n",
       "West Bengal, India     4748\n",
       "Kolkata                4061\n",
       "New Delhi              3223\n",
       "Bengaluru, India       3060\n",
       "भारत                   2629\n",
       "Mumbai                 2472\n",
       "Khajuraho              2439\n",
       "Hyderabad, India       2285\n",
       "Bhubaneshwar, India    2100\n",
       "Dhaka, Bangladesh      2082\n",
       "Pune, India            1945\n",
       "Lucknow, India         1873\n",
       "Patna, India           1790\n",
       "Uttar Pradesh, India   1718\n",
       "INDIA                  1585\n",
       "Delhi                  1564"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_loc_count = df_twt['location'].isnull().sum()\n",
    "print(f\"\"\"Please note that {no_loc_count} tweets (~{int(no_loc_count/df_twt.shape[0]*100)}% \\\n",
    "of the dataset) do not contain location info.\"\"\")\n",
    "\n",
    "top_locations = df_twt.groupby('location')\\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={0:'Count', 'location':'Location'})\\\n",
    "    .set_index('Location')\\\n",
    "    .nlargest(20, 'Count')\n",
    "\n",
    "top_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the main languages? What are the counts and proportions of tweets by languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please note that 0 tweets (~0% of the dataset) do not contain tweet language info.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>344745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>61384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn</th>\n",
       "      <td>23695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>und</th>\n",
       "      <td>11191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>6617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>4990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>3796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ht</th>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ta</th>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gu</th>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>te</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count\n",
       "Language        \n",
       "en        344745\n",
       "hi         61384\n",
       "bn         23695\n",
       "und        11191\n",
       "es          6617\n",
       "or          4990\n",
       "fr          3796\n",
       "in          2428\n",
       "ja          2248\n",
       "de          1779\n",
       "ar          1311\n",
       "ht          1311\n",
       "ta          1181\n",
       "mr           962\n",
       "tr           734\n",
       "it           692\n",
       "sv           639\n",
       "pt           513\n",
       "gu           425\n",
       "te           407"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_loc_count = df_twt.lang.isnull().sum()\n",
    "print(f\"\"\"Please note that {no_loc_count} tweets (~{int(no_loc_count/df_twt.shape[0]*100)}% \\\n",
    "of the dataset) do not contain tweet language info.\"\"\")\n",
    "\n",
    "df_twt.groupby('lang')\\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={0:'Count', 'lang':'Language'})\\\n",
    "    .set_index('Language')\\\n",
    "    .nlargest(20, 'Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please note that 0 tweets (~0% of the dataset) do not contain source info.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Android</th>\n",
       "      <td>304622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Web</th>\n",
       "      <td>70627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>52497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others/Unknown</th>\n",
       "      <td>42913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad</th>\n",
       "      <td>3760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Count\n",
       "Source                \n",
       "Android         304622\n",
       "Web              70627\n",
       "iPhone           52497\n",
       "Others/Unknown   42913\n",
       "iPad              3760"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_loc_count = df_twt.source.isnull().sum()\n",
    "print(f\"\"\"Please note that {no_loc_count} tweets (~{int(no_loc_count/df_twt.shape[0]*100)}% \\\n",
    "of the dataset) do not contain source info.\"\"\")\n",
    "\n",
    "main_sources = {\n",
    "    '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 'Android',\n",
    "    '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>': 'Web',\n",
    "    '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Mobile Web (M2)</a>': 'Web',\n",
    "    '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 'iPhone',\n",
    "    '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 'iPad',\n",
    "}\n",
    "\n",
    "df_twt['main_sources'] = df_twt['source'].apply(\n",
    "    lambda x: main_sources[x] \n",
    "    if x in main_sources.keys() \n",
    "    else 'Others/Unknown'\n",
    ")\n",
    "\n",
    "df_twt.groupby('main_sources')\\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={0:'Count', 'main_sources':'Source'})\\\n",
    "    .set_index('Source')\\\n",
    "    .nlargest(20, 'Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6f9525fed0d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"talk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m sns.lineplot(\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_places\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Counts'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m ).legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mlineplot\u001b[0;34m(x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, units, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \u001b[0mdashes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     )\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, units, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         plot_data = self.establish_variables(\n\u001b[0;32m--> 695\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/solve-iwmi/lib/python3.7/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, size, style, units, data)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Extract variable names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret input 'Country'"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "top_locations_list = top_locations.iloc[:8]\\\n",
    "    .index.tolist()\n",
    "\n",
    "df_places = df_twt[['tweet_created_at', 'location']]\n",
    "df_places.loc[:,'created_at'] = pd.to_datetime(df_places.tweet_created_at).dt.date\n",
    "df_places.loc[:,'location'] = df_places['location'].apply(\n",
    "    lambda x: x \n",
    "    if x in top_locations_list\n",
    "    else 'Others/Unknown'\n",
    ")\n",
    "\n",
    "df_places = df_places\\\n",
    "    .drop(columns='tweet_created_at')\\\n",
    "    .groupby(['created_at', 'location']).size()\\\n",
    "    .to_frame().reset_index()\\\n",
    "    .rename(columns={0:'Counts', 'location':'Location', 'created_at': 'Date'})\\\n",
    "    .sort_index()\n",
    "\n",
    "sns.set(style=\"darkgrid\", context=\"talk\")\n",
    "sns.lineplot(\n",
    "    data=df_places, hue='Country', x='Date', y='Counts'\n",
    ").legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.xticks(\n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontsize='small'  \n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "top_locations_list = top_locations.iloc[:8]\\\n",
    "    .index.tolist()\n",
    "\n",
    "df_places = df_twt[['tweet_created_at', 'location']]\n",
    "df_places.loc[:,'created_at'] = pd.to_datetime(df_places.tweet_created_at).dt.date\n",
    "df_places.loc[:,'derived.locations.country'] = df_places['location'].apply(\n",
    "    lambda x: x \n",
    "    if x in top_locations_list\n",
    "    else 'Others/Unknown'\n",
    ")\n",
    "\n",
    "df_places = df_places[~df_places['location'].isin(['Others/Unknown', 'India'])]\n",
    "\n",
    "df_places = df_places\\\n",
    "    .drop(columns='tweet_created_at')\\\n",
    "    .groupby(['created_at', 'location']).size()\\\n",
    "    .to_frame().reset_index()\\\n",
    "    .rename(columns={0:'Counts', 'location':'Location', 'created_at': 'Date'})\\\n",
    "    .sort_index()\n",
    "\n",
    "sns.set(style=\"darkgrid\", context=\"talk\")\n",
    "sns.lineplot(\n",
    "    data=df_places, hue='Country', x='Date', y='Counts'\n",
    ").legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.xticks(\n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontsize='small'  \n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on User Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "top_locations_list = top_locations.iloc[:8]\\\n",
    "    .index.tolist()\n",
    "\n",
    "df_places = df_twt[['tweet_created_at', 'users_derived_country']]\n",
    "df_places.loc[:,'created_at'] = pd.to_datetime(df_places.tweet_created_at).dt.date\n",
    "df_places.loc[:,'users_derived_country'] = df_places['users_derived_country'].apply(\n",
    "    lambda x: x \n",
    "    if x in top_locations_list\n",
    "    else 'Others/Unknown'\n",
    ")\n",
    "\n",
    "df_places = df_places[~df_places['users_derived_country'].isin(['Others/Unknown', 'India'])]\n",
    "\n",
    "df_places = df_places\\\n",
    "    .drop(columns='tweet_created_at')\\\n",
    "    .groupby(['created_at', 'users_derived_country']).size()\\\n",
    "    .to_frame().reset_index()\\\n",
    "    .rename(columns={0:'Counts', 'users_derived_country':'Country', 'created_at': 'Date'})\\\n",
    "    .sort_index()\n",
    "\n",
    "sns.set(style=\"darkgrid\", context=\"talk\")\n",
    "sns.lineplot(\n",
    "    data=df_places, hue='Country', x='Date', y='Counts'\n",
    ").legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.xticks(\n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontsize='small'  \n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## User Analysis\n",
    "### How many unique users? Verified and Protected Users Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Number of unique users: {df_users.drop_duplicates(subset='user_id').shape[0]}\n",
    "Number of verified users: {df_users.verified.sum()}\n",
    "Number of protected users: {df_users.protected.sum()}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
