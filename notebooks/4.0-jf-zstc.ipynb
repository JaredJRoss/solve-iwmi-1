{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot Text Classification Model\n",
    "**Model Description** - Bart with a classification head trained on MNLI.\n",
    "\n",
    "Sequences are posed as NLI premises and topic labels are turned into premises, i.e. business -> This text is about business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as prep\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.models import ALZeroShotWrapper\n",
    "\n",
    "#pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "ed_df = ed.read_es('localhost', 'twitter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ed_df[\n",
    "    ['tweet_id', 'lang', 'full_text']\n",
    "].to_pandas().fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_vectors = pd.read_csv('../data/results/iwmi_tweet2vec.csv')\n",
    "\n",
    "tweet_vectors['tweet_id'] = tweet_vectors['tweet_id'].astype(float).astype(int).astype(str)\n",
    "df['tweet_id'] = df['tweet_id'].astype(float).astype(int).astype(str)\n",
    "\n",
    "df = df.set_index('tweet_id').join(tweet_vectors.set_index('tweet_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tweet Preprocessing\n",
    "- Remove URLs and reserved words (RTs)\n",
    "- Remove # and @ symbols\n",
    "- Remove tweets less than 4 tokens in length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set options for the tweet-preprocessor\n",
    "prep.set_options(prep.OPT.URL, prep.OPT.RESERVED, prep.OPT.EMOJI, prep.OPT.SMILEY)\n",
    "\n",
    "## Clean text and remove #,@ symbols\n",
    "def clean_tweet(text):\n",
    "    text = prep.clean(text)\n",
    "    table = str.maketrans('','','#@')\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['full_text'].apply(lambda x: len(x.split()))\n",
    "df = df[df['length']>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.lang == 'en']\n",
    "X = df_train[[f'vec_{i}' for i in range(10)]].values\n",
    "sequences = df_train.full_text.values\n",
    "candidate_labels = [\n",
    "    'resource availability', \n",
    "    'volunteers', \n",
    "    'power supply', \n",
    "    'relief measures', \n",
    "    'food supply', \n",
    "    'infrastructure', \n",
    "    'medical assistance', \n",
    "    'rescue', \n",
    "    'shelter', \n",
    "    'utilities', \n",
    "    'water supply', \n",
    "    'evacuation', \n",
    "    'government', \n",
    "    'crime violence', \n",
    "    'mobile network', \n",
    "    'sympathy', \n",
    "    'news updates', \n",
    "    'internet', \n",
    "    'grievance'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'grievance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4743b6012a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mal_zeroshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALZeroShotWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_initial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mal_zeroshot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/research_projs/IWMI/solve-iwmi/src/models/_al_zscf.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, sequences, candidate_labels)\u001b[0m\n\u001b[1;32m    120\u001b[0m             self.y[ids] = [\n\u001b[1;32m    121\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             ]\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'grievance'"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=0)\n",
    "al_zeroshot = ALZeroShotWrapper(rfc, max_iter=100, n_initial=10, increment=10, random_state=0)\n",
    "\n",
    "al_zeroshot.fit(X, sequences, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to use the Model\n",
    "The sequence (text) is posed as a NLI Premise and the label as a hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the label is true: 98.08%\n"
     ]
    }
   ],
   "source": [
    "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
    "premise = 'Who are you voting for in 2020?'\n",
    "hypothesis = 'This text is about politics.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "logits = model(input_ids)[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "true_prob = probs[:,1].item() * 100\n",
    "print(f'Probability that the label is true: {true_prob:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Labels and Threshold for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = ['resource availability', 'volunteers', 'power supply', 'relief measures', 'food supply', 'infrastructure', 'medical assistance', 'rescue', 'shelter', 'utilities', 'water supply', 'evacuation', 'government', 'crime violence', 'mobile network', 'sympathy', 'news updates', 'internet', 'grievance']\n",
    "\n",
    "HYPOTHESES = ['This text is about '+x for x in TERMS]\n",
    "THRESHOLD = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method to get the labels for a tweet based on threshold specified'''\n",
    "def get_labels(premise, threshold=THRESHOLD):\n",
    "    topics = []\n",
    "    for idx, hypothesis in enumerate(HYPOTHESES):\n",
    "        # run through model pre-trained on MNLI\n",
    "        input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "        logits = model(input_ids)[0]\n",
    "\n",
    "        # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "        # \"entailment\" (2) as the probability of the label being true \n",
    "        entail_contradiction_logits = logits[:,[0,2]]\n",
    "        probs = entail_contradiction_logits.softmax(dim=1)\n",
    "        true_prob = probs[:,1].item() * 100\n",
    "\n",
    "        if true_prob>=threshold:\n",
    "            topics.append((TERMS[idx], np.round(true_prob,2)))\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_tweets['labels'] = df_tweets['full_text'].progress_apply(lambda x: get_labels(x, THRESHOLD))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
