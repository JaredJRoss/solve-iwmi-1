{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597854693607",
   "display_name": "Python 3.8.5 64-bit ('solve-iwmi': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot Text Classification Model\n",
    "**Model Description** - Bart with a classification head trained on MNLI.\n",
    "\n",
    "Sequences are posed as NLI premises and topic labels are turned into premises, i.e. business -> This text is about business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "from eland.conftest import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import preprocessor as prep\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data from Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_df = ed.DataFrame('localhost', 'twitter', columns=['full_text', 'user_id', 'verified', 'name', 'location', 'entities.hashtags.text', 'entities.user_mentions.name'])\n",
    "\n",
    "# defining the full-text query we need: Retrieving records for full_text_processed with the condition is_retweet=False and is_quote_status=False\n",
    "query_unique = {\n",
    "    \"bool\": {\n",
    "        \"must\": {\n",
    "            \"term\":{\"is_retweet\":\"false\"},\n",
    "        },\n",
    "        \"filter\": {\n",
    "            \"term\":{\"is_quote_status\":\"false\"},\n",
    "            \"term\":{\"lang.keyword\":\"en\"}\n",
    "        },\n",
    "    }\n",
    "}\n",
    "# using full-text search capabilities with Eland:\n",
    "df_ed = ed_df.es_query(query_unique)\n",
    "df_tweets = df_ed.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(68701, 7)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                             full_text              user_id  \\\n1264160647002103808  Praying for everyone affected by #AmphanSuperC...  1256622599364214786   \n1264160569038442496  Political differences was there, they still ex...            219183608   \n1264132382296289280  Amid #coronavirus crisis cyclone Amphan pummel...            219183608   \n1264160529100288000  West Bengal calls for Indian Army's support to...             18071358   \n1264083313699901440  Don’t send Shramik Special trains till May 26 ...             18071358   \n\n                     verified              name               location entities.hashtags.text  \\\n1264160647002103808     False       The Meraaki  Ahmadabad City, India     AmphanSuperCyclone   \n1264160569038442496     False     Sujatro Ghosh    Berlin, Deutschland                 Amphan   \n1264132382296289280     False     Sujatro Ghosh    Berlin, Deutschland            coronavirus   \n1264160529100288000      True  Zee News English                  India                    NaN   \n1264083313699901440      True  Zee News English                  India                    NaN   \n\n                    entities.user_mentions.name  \n1264160647002103808                         NaN  \n1264160569038442496                         NaN  \n1264132382296289280                         NaN  \n1264160529100288000                         NaN  \n1264083313699901440                         NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>user_id</th>\n      <th>verified</th>\n      <th>name</th>\n      <th>location</th>\n      <th>entities.hashtags.text</th>\n      <th>entities.user_mentions.name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1264160647002103808</th>\n      <td>Praying for everyone affected by #AmphanSuperC...</td>\n      <td>1256622599364214786</td>\n      <td>False</td>\n      <td>The Meraaki</td>\n      <td>Ahmadabad City, India</td>\n      <td>AmphanSuperCyclone</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1264160569038442496</th>\n      <td>Political differences was there, they still ex...</td>\n      <td>219183608</td>\n      <td>False</td>\n      <td>Sujatro Ghosh</td>\n      <td>Berlin, Deutschland</td>\n      <td>Amphan</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1264132382296289280</th>\n      <td>Amid #coronavirus crisis cyclone Amphan pummel...</td>\n      <td>219183608</td>\n      <td>False</td>\n      <td>Sujatro Ghosh</td>\n      <td>Berlin, Deutschland</td>\n      <td>coronavirus</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1264160529100288000</th>\n      <td>West Bengal calls for Indian Army's support to...</td>\n      <td>18071358</td>\n      <td>True</td>\n      <td>Zee News English</td>\n      <td>India</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1264083313699901440</th>\n      <td>Don’t send Shramik Special trains till May 26 ...</td>\n      <td>18071358</td>\n      <td>True</td>\n      <td>Zee News English</td>\n      <td>India</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tweet Preprocessing\n",
    "- Remove URLs and reserved words (RTs)\n",
    "- Remove # and @ symbols\n",
    "- Remove tweets less than 4 tokens in length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set options for the tweet-preprocessor\n",
    "prep.set_options(prep.OPT.URL, prep.OPT.RESERVED, prep.OPT.EMOJI, prep.OPT.SMILEY)\n",
    "\n",
    "## Clean text and remove #,@ symbols\n",
    "def clean_tweet(text):\n",
    "    text = prep.clean(text)\n",
    "    table = str.maketrans('','','#@')\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['full_text'] = df_tweets['full_text'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['length'] = df_tweets['full_text'].apply(lambda x: len([w for w in x.split()]))\n",
    "df_tweets = df_tweets[df_tweets['length']>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                             full_text              user_id  \\\n1264160647002103808  Praying for everyone affected by AmphanSuperCy...  1256622599364214786   \n1264160569038442496  Political differences was there, they still ex...            219183608   \n1264132382296289280  Amid coronavirus crisis cyclone Amphan pummele...            219183608   \n1264160529100288000  West Bengal calls for Indian Army's support to...             18071358   \n1264083313699901440  Dont send Shramik Special trains till May 26 i...             18071358   \n\n                     verified              name               location entities.hashtags.text  \\\n1264160647002103808     False       The Meraaki  Ahmadabad City, India     AmphanSuperCyclone   \n1264160569038442496     False     Sujatro Ghosh    Berlin, Deutschland                 Amphan   \n1264132382296289280     False     Sujatro Ghosh    Berlin, Deutschland            coronavirus   \n1264160529100288000      True  Zee News English                  India                    NaN   \n1264083313699901440      True  Zee News English                  India                    NaN   \n\n                    entities.user_mentions.name  length  \n1264160647002103808                         NaN      24  \n1264160569038442496                         NaN      11  \n1264132382296289280                         NaN      36  \n1264160529100288000                         NaN      19  \n1264083313699901440                         NaN      18  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>user_id</th>\n      <th>verified</th>\n      <th>name</th>\n      <th>location</th>\n      <th>entities.hashtags.text</th>\n      <th>entities.user_mentions.name</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1264160647002103808</th>\n      <td>Praying for everyone affected by AmphanSuperCy...</td>\n      <td>1256622599364214786</td>\n      <td>False</td>\n      <td>The Meraaki</td>\n      <td>Ahmadabad City, India</td>\n      <td>AmphanSuperCyclone</td>\n      <td>NaN</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1264160569038442496</th>\n      <td>Political differences was there, they still ex...</td>\n      <td>219183608</td>\n      <td>False</td>\n      <td>Sujatro Ghosh</td>\n      <td>Berlin, Deutschland</td>\n      <td>Amphan</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1264132382296289280</th>\n      <td>Amid coronavirus crisis cyclone Amphan pummele...</td>\n      <td>219183608</td>\n      <td>False</td>\n      <td>Sujatro Ghosh</td>\n      <td>Berlin, Deutschland</td>\n      <td>coronavirus</td>\n      <td>NaN</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1264160529100288000</th>\n      <td>West Bengal calls for Indian Army's support to...</td>\n      <td>18071358</td>\n      <td>True</td>\n      <td>Zee News English</td>\n      <td>India</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1264083313699901440</th>\n      <td>Dont send Shramik Special trains till May 26 i...</td>\n      <td>18071358</td>\n      <td>True</td>\n      <td>Zee News English</td>\n      <td>India</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to use the Model\n",
    "The sequence (text) is posed as a NLI Premise and the label as a hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probability that the label is true: 98.08%\n"
    }
   ],
   "source": [
    "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
    "premise = 'Who are you voting for in 2020?'\n",
    "hypothesis = 'This text is about politics.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "logits = model(input_ids)[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "true_prob = probs[:,1].item() * 100\n",
    "print(f'Probability that the label is true: {true_prob:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Labels and Threshold for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = ['resource availability', 'volunteers', 'power supply', 'relief measures', 'food supply', 'infrastructure', 'medical assistance', 'rescue', 'shelter', 'utilities', 'water supply', 'evacuation', 'government', 'crime violence', 'mobile network', 'sympathy', 'news updates', 'internet', 'grievance']\n",
    "\n",
    "HYPOTHESES = ['This text is about '+x for x in TERMS]\n",
    "THRESHOLD = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method to get the labels for a tweet based on threshold specified'''\n",
    "def get_labels(premise, threshold=THRESHOLD):\n",
    "    topics = []\n",
    "    for idx, hypothesis in enumerate(HYPOTHESES):\n",
    "        # run through model pre-trained on MNLI\n",
    "        input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "        logits = model(input_ids)[0]\n",
    "\n",
    "        # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "        # \"entailment\" (2) as the probability of the label being true \n",
    "        entail_contradiction_logits = logits[:,[0,2]]\n",
    "        probs = entail_contradiction_logits.softmax(dim=1)\n",
    "        true_prob = probs[:,1].item() * 100\n",
    "\n",
    "        if true_prob>=threshold:\n",
    "            topics.append((TERMS[idx], np.round(true_prob,2)))\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_tweets['labels'] = df_tweets['full_text'].progress_apply(lambda x: get_labels(x, THRESHOLD))"
   ]
  }
 ]
}