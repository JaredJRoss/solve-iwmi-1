{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot Text Classification Model\n",
    "**Model Description** - Bart with a classification head trained on MNLI.\n",
    "\n",
    "Sequences are posed as NLI premises and topic labels are turned into premises, i.e. business -> This text is about business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "from eland.conftest import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import preprocessor as prep\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data from Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_df = ed.DataFrame('localhost', 'twitter', columns=['full_text_trans'])\n",
    "\n",
    "# defining the full-text query we need: Retrieving records for full_text_processed with the condition is_retweet=False and is_quote_status=False\n",
    "query_unique = {\n",
    "    \"bool\": {\n",
    "        \"must\": {\n",
    "            \"term\":{\"is_retweet\":\"false\"},\n",
    "        },\n",
    "        \"filter\": {\n",
    "            \"term\":{\"is_quote_status\":\"false\"}\n",
    "        },\n",
    "    }\n",
    "}\n",
    "# using full-text search capabilities with Eland:\n",
    "df_ed = ed_df.es_query(query_unique)\n",
    "df_tweets = df_ed.to_pandas()\n",
    "df_tweets = df_tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(108220, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tweet Preprocessing\n",
    "- Remove URLs and reserved words (RTs)\n",
    "- Remove # and @ symbols\n",
    "- Remove tweets less than 4 tokens in length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set options for the tweet-preprocessor\n",
    "prep.set_options(prep.OPT.URL, prep.OPT.RESERVED, prep.OPT.EMOJI, prep.OPT.SMILEY)\n",
    "\n",
    "## Clean text and remove #,@ symbols\n",
    "def clean_tweet(text):\n",
    "    text = prep.clean(text)\n",
    "    table = str.maketrans('','','#@')\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['full_text_processed'] = df_tweets['full_text_trans'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['length'] = df_tweets['full_text_processed'].apply(lambda x: len([w for w in x.split()]))\n",
    "df_tweets = df_tweets[df_tweets.length != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(106937, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                               full_text_trans  \\\n",
       "1263793772833505280  #Covid19 #MigrantLabourers #Amphan and now the #planecrash near Karachi. This Eid turning out to be a perfect storm of tragedies. Also shows how nothing matters and people's deaths are mere statistics, one set of numbers replaces another. Human race to become more psychopathic.                      \n",
       "1263793968963149824  22 parties call upon Centre, seek declaration of cyclone Amphan as natural calamity | India News  \\nhttps://t.co/LykdBolAal                                                                                                                                                                                 \n",
       "1263794044691415040  @narendramodi Sir\\nIt is nice aspect of u visted Amphan cyclone affected states of odissa/W Bengal and expressed problems of people.\\nUr moral support to them will remembered ever.\\n  Praying God to be with people  affected for thier up coming early.the people will recognize ur visit and help.\\nüôè   \n",
       "1263793570474934272  The famous South Asian out-of-the-box thinking kicking in as one tries to talk to people in Amphan-ravaged areas with zero or poor connectivity . No power, no internet, no phone connection but still one tries and sometimes succeed.                                                                     \n",
       "1263793365843431424  News: Cyclone Amphan (satellite image shown) impacts eastern India and Bangladesh, killing over one hundred people and forcing the evacuation of more than four million others https://t.co/I7sFGNx738                                                                                                      \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                 full_text_processed  \\\n",
       "1263793772833505280  Covid19 MigrantLabourers Amphan and now the planecrash near Karachi. This Eid turning out to be a perfect storm of tragedies. Also shows how nothing matters and people's deaths are mere statistics, one set of numbers replaces another. Human race to become more psychopathic.                \n",
       "1263793968963149824  22 parties call upon Centre, seek declaration of cyclone Amphan as natural calamity | India News                                                                                                                                                                                                  \n",
       "1263794044691415040  narendramodi Sir It is nice aspect of u visted Amphan cyclone affected states of odissa/W Bengal and expressed problems of people. Ur moral support to them will remembered ever. Praying God to be with people affected for thier up coming early.the people will recognize ur visit and help.   \n",
       "1263793570474934272  The famous South Asian out-of-the-box thinking kicking in as one tries to talk to people in Amphan-ravaged areas with zero or poor connectivity . No power, no internet, no phone connection but still one tries and sometimes succeed.                                                           \n",
       "1263793365843431424  News: Cyclone Amphan (satellite image shown) impacts eastern India and Bangladesh, killing over one hundred people and forcing the evacuation of more than four million others                                                                                                                    \n",
       "\n",
       "                     length  \n",
       "1263793772833505280  43      \n",
       "1263793968963149824  16      \n",
       "1263794044691415040  48      \n",
       "1263793570474934272  38      \n",
       "1263793365843431424  26      "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text_trans</th>\n      <th>full_text_processed</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1263793772833505280</th>\n      <td>#Covid19 #MigrantLabourers #Amphan and now the #planecrash near Karachi. This Eid turning out to be a perfect storm of tragedies. Also shows how nothing matters and people's deaths are mere statistics, one set of numbers replaces another. Human race to become more psychopathic.</td>\n      <td>Covid19 MigrantLabourers Amphan and now the planecrash near Karachi. This Eid turning out to be a perfect storm of tragedies. Also shows how nothing matters and people's deaths are mere statistics, one set of numbers replaces another. Human race to become more psychopathic.</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>1263793968963149824</th>\n      <td>22 parties call upon Centre, seek declaration of cyclone Amphan as natural calamity | India News  \\nhttps://t.co/LykdBolAal</td>\n      <td>22 parties call upon Centre, seek declaration of cyclone Amphan as natural calamity | India News</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1263794044691415040</th>\n      <td>@narendramodi Sir\\nIt is nice aspect of u visted Amphan cyclone affected states of odissa/W Bengal and expressed problems of people.\\nUr moral support to them will remembered ever.\\n  Praying God to be with people  affected for thier up coming early.the people will recognize ur visit and help.\\nüôè</td>\n      <td>narendramodi Sir It is nice aspect of u visted Amphan cyclone affected states of odissa/W Bengal and expressed problems of people. Ur moral support to them will remembered ever. Praying God to be with people affected for thier up coming early.the people will recognize ur visit and help.</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>1263793570474934272</th>\n      <td>The famous South Asian out-of-the-box thinking kicking in as one tries to talk to people in Amphan-ravaged areas with zero or poor connectivity . No power, no internet, no phone connection but still one tries and sometimes succeed.</td>\n      <td>The famous South Asian out-of-the-box thinking kicking in as one tries to talk to people in Amphan-ravaged areas with zero or poor connectivity . No power, no internet, no phone connection but still one tries and sometimes succeed.</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>1263793365843431424</th>\n      <td>News: Cyclone Amphan (satellite image shown) impacts eastern India and Bangladesh, killing over one hundred people and forcing the evacuation of more than four million others https://t.co/I7sFGNx738</td>\n      <td>News: Cyclone Amphan (satellite image shown) impacts eastern India and Bangladesh, killing over one hundred people and forcing the evacuation of more than four million others</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU approach using Transformers Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-mnli/config.json from cache at /home/ubuntu/.cache/torch/transformers/a35b79dc26c2f371a0e19eae44d91c0a0281a5db09044517d2675703791ee3c5.746d7ef19ade685cd3ee03f131a96fab513947c26179546289ddf02a6ac683ce\n",
      "Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"entailment\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 2,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": false,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/ubuntu/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/ubuntu/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "Model card: {\n",
      "  \"caveats_and_recommendations\": {},\n",
      "  \"ethical_considerations\": {},\n",
      "  \"evaluation_data\": {},\n",
      "  \"factors\": {},\n",
      "  \"intended_use\": {},\n",
      "  \"metrics\": {},\n",
      "  \"model_details\": {},\n",
      "  \"quantitative_analyses\": {},\n",
      "  \"training_data\": {}\n",
      "}\n",
      "\n",
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-mnli/config.json from cache at /home/ubuntu/.cache/torch/transformers/a35b79dc26c2f371a0e19eae44d91c0a0281a5db09044517d2675703791ee3c5.746d7ef19ade685cd3ee03f131a96fab513947c26179546289ddf02a6ac683ce\n",
      "Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"entailment\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 2,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": false,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://cdn.huggingface.co/facebook/bart-large-mnli/pytorch_model.bin from cache at /home/ubuntu/.cache/torch/transformers/c95cb3cea0a948fd7153bdc1619ccb5af6aecfe81c1c9bc8bc68e0f996ea0e99.eeaeadf372d867602df9d8df9899a1ee0ab4210002c7c1d91f3e10b6e852657b\n",
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BartForSequenceClassification were initialized from the model checkpoint at facebook/bart-large-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = list({'sympathy', 'criticism', 'hope', 'job', 'relief measures', 'compensation', 'evacuation', 'ecosystem', 'government', \n",
    "              'corruption', 'news updates', 'volunteers', 'donation', 'cellular network', 'housing', 'farm', 'utilities', \n",
    "              'water supply', 'power supply', 'food supply', 'medical assistance', 'coronavirus', 'petition', 'poverty'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.8 ms ¬± 167 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit classifier(df_tweets['full_text_processed'][0], TERMS, multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Method to get the labels for a tweet based on threshold specified'''\n",
    "def get_all_labels(x, terms=TERMS):\n",
    "    # Run model\n",
    "    result = classifier(x, terms, multi_class=True)\n",
    "    topics = []\n",
    "    for label, score in zip(result['labels'], result['scores']):\n",
    "        topics.append((label, np.round(score,2)))\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac33ebfe9b33490d86ee5df2eb0bc2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_tweets['full_text_processed'].dropna().progress_apply(lambda x: get_all_labels(x, TERMS)).to_json('../models/zstc_labels.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('solve-iwmi': conda)",
   "display_name": "Python 3.8.5 64-bit ('solve-iwmi': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a4d2f75e1f771eece63a2be758401d0398ab9d6d1ccd3c74e88f6af3bcb0b024"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}